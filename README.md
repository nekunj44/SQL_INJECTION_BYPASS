# SQL_INJECTION_BYPASS
# ğŸ›¡ï¸ SQL Injection Detection using Machine Learning

Welcome to the **SQL Injection ML Detection** project! This repository showcases how machine learning can be leveraged to detect and classify SQL injection attacks based on query patterns. It includes model training, adversarial query generation, and bypass evaluations. ğŸ’¡

---

## ğŸ“ Project Structure

SQL_INJECTION_ML_BYPASS/
â”‚
â”œâ”€â”€ Modified_SQL_Dataset.csv # ğŸ—‚ï¸ Dataset used for training/testing
â”œâ”€â”€ common_vectorizer.pkl # ğŸ”  Shared TF-IDF vectorizer for all models
â”‚
â”œâ”€â”€ lr_model.py # ğŸ¤– Train Logistic Regression
â”œâ”€â”€ nb_model.py # ğŸ¤– Train Naive Bayes
â”œâ”€â”€ rf_model.py # ğŸ¤– Train Random Forest
â”‚
â”œâ”€â”€ lr_bypass.py # ğŸ”“ Adversarial testing for LR
â”œâ”€â”€ nb_bypass.py # ğŸ”“ Adversarial testing for NB
â”œâ”€â”€ rf_bypass.py # ğŸ”“ Adversarial testing for RF
â”‚
â”œâ”€â”€ *.pkl # ğŸ’¾ Saved models
â”œâ”€â”€ *.png # ğŸ“Š Visual results (optional)
â””â”€â”€ vectorizer_setup.py # âš™ï¸ TF-IDF Vectorizer setup

---

## ğŸ” Objective

To train and evaluate machine learning models for detecting SQL injection attacks and test their robustness using **super-aggressive adversarial techniques**.

---

## ğŸš€ Models Implemented

- âœ… **Logistic Regression**
- âœ… **Naive Bayes**
- âœ… **Random Forest**

All models are trained using TF-IDF vectorization and evaluated for:

- Accuracy
- Precision, Recall, F1-score
- Robustness against adversarial SQL injections

---

## ğŸ§ª Adversarial Techniques Used

- ğŸ” **Homoglyph Replacement**  
- ğŸ§© **Fragmented Keywords using SQL Comments**  
- ğŸŒ **Multi-layered URL Encoding**  
- ğŸ­ **Cloaking payloads in nested queries**  
- â³ **Time-based injections with `SLEEP()`**

Each bypass script randomly applies 3 transformations to generate super-aggressive queries.

---

## ğŸ“Š Sample Bypass Results

| Model               | Total Malicious Queries | Bypassed | 
|---------------------|-------------------------|----------|
| Logistic Regression | 11382                   | 6283     | 
| Naive Bayes         | 11382                   | 956      | 
| Random Forest       | 11382                   | 2714     | 

ğŸ§  Key Insights
ML models can detect SQL injection patterns effectively.

However, they are vulnerable to obfuscation and bypass attacks.

Robust input sanitization + adversarial training is essential for production systems.

ğŸ§‘â€ğŸ’» Author
Nekunj Khanna
ğŸ”— LinkedIn
ğŸ“ GitHub

â­ If you found this useful, give it a star!










